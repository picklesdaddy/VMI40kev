{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import SimpleITK as sitk\n",
    "import monai\n",
    "import itertools\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    ToTensor,\n",
    "    ScaleIntensityRange,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "from networks.add_net.generator import UnetGenerator\n",
    "from networks.add_net.discriminator import ConditionalDiscriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__\n",
    "set_determinism(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_path = glob.glob('D:/DeepLearning/image2image/train/VMI40/*.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annos_path = glob.glob('D:/DeepLearning/image2image/train/CI/*.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(annos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_path[:3], annos_path[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i, img_path in enumerate(imgs_path[:4]):\n",
    "    img = sitk.ReadImage(img_path)\n",
    "    img_np = sitk.GetArrayFromImage(img)\n",
    "    img_np = np.expand_dims(img_np, axis=0)\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(img_np[0,:,:], cmap='gray')\n",
    "    plt.title(img_path.split('\\\\')[-1])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i, img_path in enumerate(annos_path[:4]):\n",
    "    img = sitk.ReadImage(img_path)\n",
    "    img_np = sitk.GetArrayFromImage(img)\n",
    "    img_np = np.expand_dims(img_np, axis=0)\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(img_np[0,:,:], cmap='gray')\n",
    "    plt.title(img_path.split('\\\\')[-1])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform = Compose([ScaleIntensity(minv=-1, maxv=1), ToTensor()])\n",
    "transform = Compose([ScaleIntensityRange(a_min=-1000, a_max=3700, b_min=-1, b_max=1,clip=True), ToTensor()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nii_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, annos_path,imgs_path):\n",
    "        self.imgs_path = imgs_path\n",
    "        self.annos_path = annos_path\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        anno_path = self.annos_path[index]\n",
    "        anno = sitk.ReadImage(anno_path)\n",
    "        anno_np = sitk.GetArrayFromImage(anno).astype(np.float32)\n",
    "        anno_np = np.expand_dims(anno_np, axis=0)\n",
    "        anno_tensor = transform(anno_np)\n",
    "        img_path = self.imgs_path[index]\n",
    "        img = sitk.ReadImage(img_path)\n",
    "        img_np = sitk.GetArrayFromImage(img).astype(np.float32)\n",
    "        img_np = np.expand_dims(img_np, axis=0)\n",
    "        #print(img_np.shape)\n",
    "        img_tensor = transform(img_np)\n",
    "\n",
    "        return anno_tensor,img_tensor\n",
    "    def __len__(self):\n",
    "        return len(self.imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = nii_dataset(annos_path, imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annos_batch, imgs_batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annos_batch.shape, imgs_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(annos_batch[0].numpy()[0,:,:],cmap='gray')\n",
    "sitk.WriteImage(sitk.GetImageFromArray(annos_batch[0]), './annos_batch.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,20))\n",
    "for i, (anno, img) in enumerate(zip(annos_batch[:4], imgs_batch[:4])):\n",
    "    anno = (anno.numpy() +1)/2\n",
    "    img = (img.numpy() +1)/2\n",
    "    plt.subplot(4,2,2*i+1)\n",
    "    plt.imshow(anno[0,:,:], cmap='gray')\n",
    "    plt.title('input image')\n",
    "    plt.subplot(4,2,2*i+2)\n",
    "    plt.imshow(img[0,:,:], cmap='gray')\n",
    "    plt.title('output image')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs_path = glob.glob('D:/DeepLearning/image2image/test/40kev/*.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_annos_path = glob.glob('D:/DeepLearning/image2image/test/CI/*.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_annos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = nii_dataset(test_annos_path, test_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annos_batch, imgs_batch = next(iter(dataloader_test))\n",
    "\n",
    "plt.figure(figsize=(10,20))\n",
    "for i, (anno, img) in enumerate(zip(annos_batch[:4], imgs_batch[:4])):\n",
    "    anno = (anno.numpy() + 1)/2\n",
    "    img = (img.numpy() + 1)/2\n",
    "    plt.subplot(4,2,2*i+1)\n",
    "    plt.imshow(anno[0,:,:], cmap='gray')\n",
    "    plt.title('input image')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(4,2,2*i+2)\n",
    "    plt.imshow(img[0,:,:], cmap='gray')\n",
    "    plt.title('output image')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gen = UnetGenerator().to(device)\n",
    "#gen = AttentionUnet(spatial_dims=2, in_channels=1, out_channels=1, channels=(32,64,128,256,512), strides=(2,2,2,2,1)).to(device)\n",
    "#gen = UNet(spatial_dims=2,in_channels=1,out_channels=1,channels=(32,64,128,256,256),strides=(2,2,2,2),num_res_units=2).to(device)\n",
    "#gen =  UNETR(in_channels=1,out_channels=1,img_size=(512,512),feature_size=16,hidden_size=768,mlp_dim=3072,num_heads=12,norm_name=\"instance\",res_block=True,dropout_rate=0.0,spatial_dims=2).to(device)\n",
    "dis = ConditionalDiscriminator().to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "dis_optimizer = optim.Adam(dis.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "gen_optimizer = optim.Adam(gen.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.rand(1,1,512,512).to(device)\n",
    "output = gen(input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import netron\n",
    "import torch.onnx\n",
    "input = torch.rand(1,1,512,512).to(device)\n",
    "output = gen(input)\n",
    "onnx_path = \"netForwatch.onnx\"\n",
    "torch.onnx.export(gen, input, onnx_path,export_params=True,opset_version=11) #输入可视化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_window(image_array):\n",
    "    image_array = image_array.astype(np.float32)\n",
    "    image_array = -1000 + 2350 * (image_array - image_array.min())\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generater_images(model, test_input, true_traget):\n",
    "    prediction = model(test_input).permute(0,2,3,1).detach().cpu().numpy()\n",
    "    prediction = (prediction + 1)/2\n",
    "    test_input = test_input.permute(0,2,3,1).detach().cpu().numpy()\n",
    "    true_traget = true_traget.permute(0,2,3,1).detach().cpu().numpy()\n",
    "    plt.figure(figsize=(15,15))\n",
    "    display_list = [test_input[12], true_traget[12], prediction[12]]\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LAMBDA = 7\n",
    "imgs_batch = imgs_batch.to(device)\n",
    "annos_batch = annos_batch.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, annos_path):\n",
    "        self.annos_path = annos_path\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        anno_path = self.annos_path[index]\n",
    "        anno = sitk.ReadImage(anno_path)\n",
    "        anno_np = sitk.GetArrayFromImage(anno).astype(np.float32)\n",
    "        anno_np = np.expand_dims(anno_np, axis=0)\n",
    "        anno_tensor = transform(anno_np)\n",
    "        return anno_tensor\n",
    "    def __len__(self):\n",
    "        return len(self.annos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CI_test = test_dataset(test_annos_path)\n",
    "test_dataloader = torch.utils.data.DataLoader(CI_test, batch_size = 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_loss = []\n",
    "G_loss = []\n",
    "\n",
    "for epoch in range(250):\n",
    "    D_epoch_loss = 0\n",
    "    G_epoch_loss = 0\n",
    "    count = len(dataloader)\n",
    "    for step, (annos, imgs) in enumerate(dataloader):\n",
    "        imgs = imgs.to(device)\n",
    "        annos = annos.to(device)\n",
    "        for p in dis.parameters(): \n",
    "            p.data.clamp_(-0.01, 0.01) # clamp parameters between -0.01 and 0.01\n",
    "        dis_optimizer.zero_grad()\n",
    "        dis_real_output = dis(annos, imgs) #输入真实的成对图片\n",
    "        dis_real_loss = loss_fn(dis_real_output, torch.ones_like(dis_real_output, device=device))# 希望真实的图片判定为1\n",
    "        dis_real_loss.backward()\n",
    "        gen_output = gen(annos)\n",
    "        #\n",
    "        dis_fake_output = dis(annos, gen_output.detach())#\n",
    "        dis_fake_loss =  loss_fn(dis_fake_output, torch.zeros_like(dis_fake_output, device=device))\n",
    "        dis_fake_loss.backward()\n",
    "\n",
    "        dis_loss = dis_real_loss + dis_fake_loss\n",
    "        dis_optimizer.step()\n",
    "\n",
    "        if epoch < 10:\n",
    "            LAMBDA = 0.5  \n",
    "        elif epoch < 20:\n",
    "            LAMBDA = 1\n",
    "        elif epoch < 30:\n",
    "            LAMBDA = 5  \n",
    "        elif epoch <60:\n",
    "            LAMBDA = 10\n",
    "        else:\n",
    "            LAMBDA = 20  \n",
    "        gen_optimizer.zero_grad()\n",
    "        dis_gen_output = dis(annos, gen_output)\n",
    "        gen_loss_cross_entropy = loss_fn(dis_gen_output, torch.ones_like(dis_gen_output, device=device)) #\n",
    "        gen_loss_L1 = torch.mean(torch.abs(imgs - gen_output))\n",
    "        gen_loss = gen_loss_cross_entropy + (LAMBDA * gen_loss_L1)\n",
    "        gen_loss.backward()\n",
    "        gen_optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            D_epoch_loss += dis_loss.item()\n",
    "            G_epoch_loss += gen_loss.item()\n",
    "        #    generater_images(gen, imgs_batch, annos_batch)\n",
    "    with torch.no_grad():\n",
    "        D_epoch_loss /= count\n",
    "        G_epoch_loss /= count\n",
    "        D_loss.append(D_epoch_loss)\n",
    "        G_loss.append(G_epoch_loss)\n",
    "        state = {'model':gen.state_dict(), 'optimizer':gen_optimizer.state_dict(), 'epoch':epoch}\n",
    "        if epoch % 2 == 0:\n",
    "            print('Epoch [{}/{}], D_loss: {:.4f}, G_loss: {:.4f}'.format(epoch, 200, D_epoch_loss, G_epoch_loss))\n",
    "            generater_images(gen, annos_batch, imgs_batch)\n",
    "            plt.plot(D_loss, label='D_loss')\n",
    "            plt.plot(G_loss, label='G_loss')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            torch.save(gen.state_dict(), \"saved_models/gen_%d.pth\" % epoch)\n",
    "    #        torch.save(dis.state_dict(), 'saved_models/dis_%d.pth\" % epoch')\n",
    "            print('Saved model')\n",
    "            temp = gen(next(iter(test_dataloader)).to(device)).permute(0,2,3,1).detach().cpu().numpy()\n",
    "        #    temp = gen_output.permute(0,2,3,1).detach().cpu().numpy()\n",
    "        #    sitk.WriteImage(sitk.GetImageFromArray(temp), './data/'+str(epoch)+'.nii.gz')\n",
    "            sitk.WriteImage(sitk.GetImageFromArray(set_window(temp)), './data/'+str(epoch)+'.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_loss = []\n",
    "G_loss = []\n",
    "\n",
    "for epoch in range(250):\n",
    "    D_epoch_loss = 0\n",
    "    G_epoch_loss = 0\n",
    "    count = len(dataloader)\n",
    "    for step, (annos, imgs) in enumerate(dataloader):\n",
    "        imgs = imgs.to(device)\n",
    "        annos = annos.to(device)\n",
    "        for p in dis.parameters(): \n",
    "            p.data.clamp_(-0.01, 0.01) # clamp parameters between -0.01 and 0.01\n",
    "        dis_optimizer.zero_grad()\n",
    "        dis_real_output = dis(annos, imgs) #输入真实的成对图片\n",
    "        dis_real_loss = loss_fn(dis_real_output, torch.ones_like(dis_real_output, device=device))# 希望真实的图片判定为1\n",
    "        dis_real_loss.backward()\n",
    "        gen_output = gen(annos)\n",
    "        #\n",
    "        dis_fake_output = dis(annos, gen_output.detach())#\n",
    "        dis_fake_loss =  loss_fn(dis_fake_output, torch.zeros_like(dis_fake_output, device=device))\n",
    "        dis_fake_loss.backward()\n",
    "\n",
    "        dis_loss = dis_real_loss + dis_fake_loss\n",
    "        dis_optimizer.step()\n",
    "        gen_optimizer.zero_grad()\n",
    "        dis_gen_output = dis(annos, gen_output)\n",
    "        gen_loss_cross_entropy = loss_fn(dis_gen_output, torch.ones_like(dis_gen_output, device=device)) #\n",
    "        gen_loss_L1 = torch.mean(torch.abs(imgs - gen_output))\n",
    "        gen_loss = gen_loss_cross_entropy + (LAMBDA * gen_loss_L1)\n",
    "        gen_loss.backward()\n",
    "        gen_optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            D_epoch_loss += dis_loss.item()\n",
    "            G_epoch_loss += gen_loss.item()\n",
    "        #    generater_images(gen, imgs_batch, annos_batch)\n",
    "    with torch.no_grad():\n",
    "        D_epoch_loss /= count\n",
    "        G_epoch_loss /= count\n",
    "        D_loss.append(D_epoch_loss)\n",
    "        G_loss.append(G_epoch_loss)\n",
    "        state = {'model':gen.state_dict(), 'optimizer':gen_optimizer.state_dict(), 'epoch':epoch}\n",
    "        if epoch % 2 == 0:\n",
    "            print('Epoch [{}/{}], D_loss: {:.4f}, G_loss: {:.4f}'.format(epoch, 200, D_epoch_loss, G_epoch_loss))\n",
    "            generater_images(gen, annos_batch, imgs_batch)\n",
    "            plt.plot(D_loss, label='D_loss')\n",
    "            plt.plot(G_loss, label='G_loss')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            torch.save(gen.state_dict(), \"saved_models/gen_%d.pth\" % epoch)\n",
    "    #        torch.save(dis.state_dict(), 'saved_models/dis_%d.pth\" % epoch')\n",
    "            print('Saved model')\n",
    "            temp = gen(next(iter(test_dataloader)).to(device)).permute(0,2,3,1).detach().cpu().numpy()\n",
    "        #    temp = gen_output.permute(0,2,3,1).detach().cpu().numpy()\n",
    "        #    sitk.WriteImage(sitk.GetImageFromArray(temp), './data/'+str(epoch)+'.nii.gz')\n",
    "            sitk.WriteImage(sitk.GetImageFromArray(set_window(temp)), './data/'+str(epoch)+'.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, annos_path):\n",
    "        self.annos_path = annos_path\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        anno_path = self.annos_path[index]\n",
    "        anno = sitk.ReadImage(anno_path)\n",
    "        anno_np = sitk.GetArrayFromImage(anno).astype(np.float32)\n",
    "        anno_np = np.expand_dims(anno_np, axis=0)\n",
    "        anno_tensor = transform(anno_np)\n",
    "        return anno_tensor\n",
    "    def __len__(self):\n",
    "        return len(self.annos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VMI_test = test_dataset(test_annos_path)\n",
    "test_dataloader = torch.utils.data.DataLoader(VMI_test, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(VMI_test, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dataset = 'D:/DeepLearning/image2image/gen_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用fid判断生成的图像与原图像的判断那个权重生成的图像最好。\n",
    "#gen.load_state_dict(torch.load(\"saved_models/gen_74.pth\")) #恢复torch的权重\n",
    "gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image in enumerate(test_dataloader):\n",
    "    gen_ID = gen(image.to(device))\n",
    "    img_array = np.squeeze(gen_ID.cpu().data.numpy())\n",
    "#    img_array = (img_array + 1)/2\n",
    "    file_name = test_dataloader.dataset.annos_path[i].split('\\\\')[-1].split('.')[0]\n",
    "    spacing = sitk.ReadImage(test_dataloader.dataset.annos_path[i]).GetSpacing()\n",
    "    direction = sitk.ReadImage(test_dataloader.dataset.annos_path[i]).GetDirection()\n",
    "    orign = sitk.ReadImage(test_dataloader.dataset.annos_path[i]).GetOrigin()\n",
    "    temp = sitk.GetImageFromArray(set_window(img_array))\n",
    "    temp.SetSpacing(spacing)\n",
    "    temp.SetDirection(direction)\n",
    "    temp.SetOrigin(orign)\n",
    "    sitk_seg = sitk.Threshold(temp, lower=-1000, upper=3700, outsideValue=-1001) #设置中值滤波器\n",
    "    sitk_median = sitk.MedianImageFilter()\n",
    "    sitk_median.SetRadius(1)\n",
    "    sitk_median = sitk_median.Execute(sitk_seg)\n",
    "    sitk.WriteImage(sitk_median,os.path.join(gen_dataset,'gen_ID_%s.nii.gz'% (str(file_name))))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in np.arange(150,250,2):\n",
    "    gen.load_state_dict(torch.load(\"saved_models/gen_{}.pth\".format(e))) #恢复torch的权重\n",
    "    os.mkdir('D:/DeepLearning/image2image/gen_data/model_{}'.format(e))\n",
    "    for i, image in enumerate(test_dataloader):\n",
    "        gen_ID = gen(image.to(device))\n",
    "        img_array = np.squeeze(gen_ID.cpu().data.numpy())\n",
    "        file_name = test_dataloader.dataset.annos_path[i].split('\\\\')[-1].split('.')[0]\n",
    "        spacing = sitk.ReadImage(test_dataloader.dataset.annos_path[i]).GetSpacing()\n",
    "        direction = sitk.ReadImage(test_dataloader.dataset.annos_path[i]).GetDirection()\n",
    "        orign = sitk.ReadImage(test_dataloader.dataset.annos_path[i]).GetOrigin()\n",
    "        temp = sitk.GetImageFromArray(set_window(img_array))\n",
    "        temp.SetSpacing(spacing)\n",
    "        temp.SetDirection(direction)\n",
    "        temp.SetOrigin(orign)\n",
    "        sitk_seg = sitk.Threshold(temp, lower=-1000, upper=3700, outsideValue=-1001) #设置中值滤波器\n",
    "        sitk_median = sitk.MedianImageFilter()\n",
    "        sitk_median.SetRadius(5)\n",
    "        sitk_median = sitk_median.Execute(sitk_seg)\n",
    "        sitk.WriteImage(temp,os.path.join('D:/DeepLearning/image2image/gen_data/model_{}'.format(e),'gen_ID_%s.nii.gz'% (str(file_name))))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对图像进行中值滤波\n",
    "path = 'D:/VSCODE/GAN_pytorch/gen_data/gen_ID_BaiYaoYao024.nii.gz'\n",
    "image = sitk.ReadImage(path)\n",
    "sitk_seg = sitk.Threshold(image, lower=-1000, upper=3700, outsideValue=-1001)\n",
    "sitk_median = sitk.MedianImageFilter()\n",
    "sitk_median.SetRadius(1)\n",
    "sitk_median = sitk_median.Execute(sitk_seg)\n",
    "sitk.WriteImage(sitk_median, 'D:/VSCODE/GAN_pytorch/median_filtering/gen_ID_BaiYaoYao024.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3b09f0dae079356b11e2992c8ce1698bd60fda55aea4c87f004ec164747e9c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
